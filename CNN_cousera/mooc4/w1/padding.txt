Padding trong Xử lý Ảnh và Học Sâu
Padding là một kỹ thuật được sử dụng trong xử lý ảnh và học sâu (deep learning) để thêm các giá trị xung quanh biên của ảnh hoặc ma trận đầu vào. Mục đích chính của padding là bảo toàn kích thước không gian của đầu vào sau khi áp dụng các phép biến đổi như convolution.

Các loại Padding
Valid Padding (No Padding):

Không thêm bất kỳ giá trị nào xung quanh biên của đầu vào.
Kích thước đầu ra sẽ nhỏ hơn kích thước đầu vào.
Công thức: 
Output size
=
Input size
−
Kernel size
+
1
Output size=Input size−Kernel size+1
Same Padding:

Thêm giá trị xung quanh biên của đầu vào sao cho kích thước đầu ra bằng với kích thước đầu vào.
Công thức: 
Output size
=
Input size
Output size=Input size
Zero Padding:

Thêm các giá trị 0 xung quanh biên của đầu vào.
Thường được sử dụng để giữ nguyên kích thước không gian của đầu vào sau khi áp dụng convolution.
Reflect Padding:

Thêm giá trị phản chiếu của các phần tử biên của đầu vào.
Replicate Padding:

Thêm giá trị của các phần tử biên của đầu vào mà không thay đổi giá trị.
Ứng dụng của Padding
Bảo toàn kích thước đầu vào:

Khi áp dụng các phép biến đổi như convolution, kích thước đầu ra thường bị giảm. Padding giúp bảo toàn kích thước ban đầu của đầu vào.
Giữ nguyên thông tin biên:

Biên của ảnh hoặc ma trận đầu vào thường chứa thông tin quan trọng. Padding giúp đảm bảo rằng thông tin này không bị mất đi trong quá trình xử lý.
Giảm mất mát thông tin:

Khi không sử dụng padding, các phần tử ở biên có thể bị mất thông tin do không được tính đến trong các phép biến đổi. Padding giúp giảm thiểu việc mất mát thông tin này.
Ví dụ về Padding trong Convolutional Neural Networks (CNN)
Giả sử bạn có một ảnh đầu vào kích thước 
5
×
5
5×5 và một kernel kích thước 
3
×
3
3×3:

Không dùng padding (Valid Padding):

Đầu ra sẽ có kích thước 
3
×
3
3×3 vì biên của ảnh không được tính.
Dùng zero padding (Same Padding):

Thêm một lớp 0 xung quanh biên của ảnh, làm cho kích thước ảnh trở thành 
7
×
7
7×7.
Đầu ra sẽ có kích thước 
5
×
5
5×5, giống với kích thước đầu vào.